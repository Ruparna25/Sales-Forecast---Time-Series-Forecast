{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Preprocess the dataset","metadata":{}},{"cell_type":"code","source":"def data_preprocessing(df,holiday_events_df,oil_df,lag_days=[1,7,30],rolling_days=[7,30,60]):\n    \n    start_date=pd.to_datetime(df['date'].agg(['min','max'])['min'])\n    end_date=pd.to_datetime(df['date'].agg(['min','max'])['max'])\n    date_df = pd.DataFrame()\n    date_df['date']=pd.date_range(start=start_date,end=end_date)\n    unique_store_df=pd.DataFrame({'store_nbr':df['store_nbr'].unique()})\n    \n    date_df = cartesian(date_df,unique_store_df)\n    \n    df=date_df.merge(df,how='left',on=['date','store_nbr'])\n    df=df[df['sales']>0.0]\n    \n    le=LabelEncoder()\n    df['family']=le.fit_transform(df[['family']])\n  \n    #Create date features\n    df['day_of_month']=df['date'].dt.day\n    df['day_of_week']=df['date'].dt.dayofweek\n    df['day_of_year']=df['date'].dt.dayofyear\n    df['month']=df['date'].dt.month\n    df['year']=df['date'].dt.year\n    df['is_weekend']=(df['day_of_week'] > 5).astype(np.int8)\n    \n    #handling null values\n    df['sales']=df.groupby(['store_nbr','day_of_week'])['sales'].ffill()\n    \n    #creating lag features\n    SHIFT = 15\n    for l in lag_days:\n        df['lag_{}'.format(l)]=df.groupby(['store_nbr','family','day_of_week'])['sales'].transform(lambda x: x.shift(SHIFT+l)).fillna(0.0)\n        \n    #creating rolling features\n    for r in rolling_days:\n        df['rolling_mean_{}'.format(r)]=df.groupby(['store_nbr','family','day_of_week'])['sales'].transform(lambda x:x.shift(SHIFT).rolling(r,min_periods=1).mean()).fillna(0.0)\n    \n    #merging oil data\n    oil_df['date']=pd.to_datetime(oil_df['date'])\n    oil_df = oil_df.rename(columns={\"dcoilwtico\": \"oil_price\"})\n    df=df.merge(oil_df,how='left',on='date')\n    \n    #filling in missing values\n    df['oil_price']=df['oil_price'].fillna(axis=0,method='ffill')\n    #to fill data for the first day we will use the mean price from the 2nd day\n    oil_price=df[df['date']=='2013-01-02']['oil_price']\n    oil_price=round(np.mean(oil_price))\n    df['oil_price']=df['oil_price'].fillna(oil_price)\n    \n    #merging holiday data\n    holiday_events_df['date'] = pd.to_datetime(holiday_events_df['date'])\n    #holiday_events_df['type']=holiday_events_df['type'].replace(['Transfer','Additional','Bridge','Event'],'Holiday')\n    #holiday_events_df=holiday_events_df.drop(['locale','locale_name','description','transferred'],axis=1)\n    #holiday_events_df = holiday_events_df.rename(columns={\"type\": \"day_type\"})\n    df=df.merge(holiday_events_df[['date','day_type']],how='left',on='date')\n    df['day_type'].fillna(False, inplace=True)\n    df['day_type']=df['day_type'].astype(bool).astype(int)\n    \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-13T06:25:41.471998Z","iopub.execute_input":"2022-05-13T06:25:41.472415Z","iopub.status.idle":"2022-05-13T06:25:41.513884Z","shell.execute_reply.started":"2022-05-13T06:25:41.472311Z","shell.execute_reply":"2022-05-13T06:25:41.513209Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Preprocessing data -\ndf=data_preprocessing(data,holidays,oil,lag_days = [1, 7, 14],rolling_days =  [7, 30, 60])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Divide the data into train, valid and test set\ndf['date'] = pd.to_datetime(df['date'])\ntrain_startdate = df['date'] >= '2014-01-01'\ntrain_enddate = df['date'] <= '2016-12-31'\ntrain_duration = train_startdate & train_enddate\ntraindata = df.loc[train_duration]\n\nval_startdate = df['date'] >= '2017-01-01'\nval_enddate = df['date'] <= '2017-03-31'\nval_duration = val_startdate & val_enddate\nval_data = df.loc[val_duration]\n\ntest_startdate = df['date'] >= '2017-04-01'\ntest_enddate = df['date'] <= '2017-04-15'\ntest_duration = test_startdate & test_enddate\ntest_data = df.loc[test_duration]\n\n\ny_train = traindata.sales\nX_train = traindata.drop(['sales', 'date'], axis=1)\n\ny_val = val_data.sales\nX_val = val_data.drop(['sales', 'date'], axis=1)\n\ny_test = test_data.sales\nX_test = test_data.drop(['sales', 'date'], axis=1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Generating time series from the available training data\nnum_feature_input = len(X_train.columns)\n\nhistory_input = 30\ngenerator = TimeseriesGenerator(X_train, y_train, length=history_input, batch_size = 1)\n\nfor i in range(len(generator)):\n    x, y = generator[i]\n    print('%s => %s' % (x, y))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-05-13T06:28:17.179778Z","iopub.execute_input":"2022-05-13T06:28:17.180344Z","iopub.status.idle":"2022-05-13T06:28:17.184089Z","shell.execute_reply.started":"2022-05-13T06:28:17.180281Z","shell.execute_reply":"2022-05-13T06:28:17.183344Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Model","metadata":{}},{"cell_type":"code","source":"with tf.device('/GPU:0'):\n    def MultiStepLSTM_model():\n        model = Sequential()\n        model.add(LSTM(units = 50, activation='relu', return_sequences = True, input_shape = (history_input, num_feature_input)))\n        model.add(Dropout(0.2))\n        \n        model.add(LSTM(units = 50))\n        model.add(Dropout(0.2))\n        model.add(Dense(units=1, activation = \"linear\"))\n        return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/GPU:0'):\n    model = MultiStepLSTM_model()\n    model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/GPU:0'):\n    model.compile(optimizer='adam', loss='mean_squared_error', metrics = ['accuracy'])\n    model.fit_generator(generator, steps_per_epoch=len(generator)/4, epochs=20, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}